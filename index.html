<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Inferential Statistics - Complete Tutorial</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="logo">
                <span class="logo-icon">üìä</span>
                <span class="logo-text">Inferential Statistics</span>
            </div>
            <button class="menu-toggle" id="menuToggle">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu" id="navMenu">
                <li><a href="#home" class="nav-link active">Home</a></li>
                <li><a href="#intro" class="nav-link">Introduction</a></li>
                <li><a href="#hypothesis" class="nav-link">Hypothesis Testing</a></li>
                <li><a href="#confidence" class="nav-link">Confidence Intervals</a></li>
                <li><a href="#tests" class="nav-link">Statistical Tests</a></li>
                <li><a href="#regression" class="nav-link">Regression</a></li>
                <li><a href="#calculator" class="nav-link">Calculator</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <section id="home" class="hero">
        <div class="hero-content">
            <h1 class="hero-title">Master Inferential Statistics</h1>
            <p class="hero-subtitle">Your comprehensive guide to understanding statistical inference, hypothesis testing, and data-driven decision making</p>
            <button class="cta-button" onclick="scrollToSection('intro')">Start Learning</button>
        </div>
        <div class="hero-animation">
            <div class="floating-stat" style="top: 20%; left: 15%;">Œº</div>
            <div class="floating-stat" style="top: 60%; left: 10%;">œÉ</div>
            <div class="floating-stat" style="top: 30%; right: 20%;">Œ±</div>
            <div class="floating-stat" style="top: 70%; right: 15%;">Œ≤</div>
            <div class="floating-stat" style="top: 45%; left: 50%;">p</div>
        </div>
    </section>

    <!-- Introduction Section -->
    <section id="intro" class="section">
        <div class="container">
            <h2 class="section-title">What is Inferential Statistics?</h2>
            <div class="content-grid">
                <div class="content-card">
                    <div class="card-icon">üéØ</div>
                    <h3>Making Predictions</h3>
                    <p>Use sample data to make predictions and inferences about a larger population</p>
                </div>
                <div class="content-card">
                    <div class="card-icon">üîç</div>
                    <h3>Testing Hypotheses</h3>
                    <p>Scientifically test claims and theories using statistical evidence</p>
                </div>
                <div class="content-card">
                    <div class="card-icon">üìà</div>
                    <h3>Drawing Conclusions</h3>
                    <p>Make data-driven decisions with quantified confidence levels</p>
                </div>
            </div>
            
            <div class="theory-box">
                <h3>Fundamental Concepts in Inferential Statistics</h3>
                <div class="concept-list">
                    <div class="concept-item">
                        <strong>Population vs Sample:</strong> A population (denoted N) includes all members of a specified group that we want to study. A sample (denoted n) is a smaller subset randomly selected from the population to make inferences about the whole. Since studying entire populations is often impractical or impossible, we use representative samples to estimate population characteristics.
                    </div>
                    <div class="concept-item">
                        <strong>Parameters vs Statistics:</strong> 
                        <br>‚Ä¢ <strong>Parameters</strong> (Greek letters): Unknown population values we want to estimate
                        <br>&nbsp;&nbsp;- Œº (mu): Population mean
                        <br>&nbsp;&nbsp;- œÉ (sigma): Population standard deviation  
                        <br>&nbsp;&nbsp;- œÉ¬≤ (sigma squared): Population variance
                        <br>&nbsp;&nbsp;- p: Population proportion
                        <br>‚Ä¢ <strong>Statistics</strong> (Roman letters): Known sample values calculated from data
                        <br>&nbsp;&nbsp;- xÃÑ (x-bar): Sample mean
                        <br>&nbsp;&nbsp;- s: Sample standard deviation
                        <br>&nbsp;&nbsp;- s¬≤: Sample variance
                        <br>&nbsp;&nbsp;- pÃÇ (p-hat): Sample proportion
                    </div>
                    <div class="concept-item">
                        <strong>Central Limit Theorem (CLT):</strong> One of the most important theorems in statistics. For any population with mean Œº and standard deviation œÉ, as sample size n increases (typically n ‚â• 30), the sampling distribution of the sample mean xÃÑ approaches a normal distribution with:
                        <br>‚Ä¢ Mean: Œº<sub>xÃÑ</sub> = Œº
                        <br>‚Ä¢ Standard Error: œÉ<sub>xÃÑ</sub> = œÉ / ‚àön
                        <br>This holds regardless of the shape of the original population distribution!
                    </div>
                    <div class="concept-item">
                        <strong>Standard Error (SE):</strong> The standard deviation of a sampling distribution. It measures how much sample statistics typically vary from the population parameter. Formula: SE = s / ‚àön, where s is the sample standard deviation and n is the sample size. Larger samples have smaller standard errors, leading to more precise estimates.
                    </div>
                    <div class="concept-item">
                        <strong>Sampling Distribution:</strong> The probability distribution of a statistic (like xÃÑ or pÃÇ) obtained from all possible samples of a given size from a population. Understanding sampling distributions is crucial for making inferences about populations from samples.
                    </div>
                    <div class="concept-item">
                        <strong>Law of Large Numbers:</strong> As the sample size increases, the sample mean xÃÑ converges to the population mean Œº. This justifies using sample statistics to estimate population parameters.
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Hypothesis Testing Section -->
    <section id="hypothesis" class="section bg-alternate">
        <div class="container">
            <h2 class="section-title">Hypothesis Testing</h2>
            
            <div class="info-box">
                <p class="intro-text">Hypothesis testing is a systematic statistical method used to make decisions about population parameters based on sample data. It provides a framework for determining whether observed differences or effects are statistically significant or merely due to random chance.</p>
            </div>

            <div class="steps-container">
                <div class="step-card">
                    <div class="step-number">1</div>
                    <h3>State Hypotheses</h3>
                    <p><strong>H‚ÇÄ (Null Hypothesis):</strong> The default assumption stating no effect, no difference, or no relationship exists (e.g., Œº = Œº‚ÇÄ or p‚ÇÅ = p‚ÇÇ)</p>
                    <p><strong>H‚ÇÅ or H<sub>a</sub> (Alternative Hypothesis):</strong> The research claim we're trying to prove. Can be:</p>
                    <p>‚Ä¢ <strong>Two-tailed:</strong> Œº ‚â† Œº‚ÇÄ (tests for any difference)</p>
                    <p>‚Ä¢ <strong>Right-tailed:</strong> Œº > Œº‚ÇÄ (tests for increase)</p>
                    <p>‚Ä¢ <strong>Left-tailed:</strong> Œº < Œº‚ÇÄ (tests for decrease)</p>
                </div>
                <div class="step-card">
                    <div class="step-number">2</div>
                    <h3>Set Significance Level</h3>
                    <p><strong>Œ± (Alpha):</strong> Maximum probability of Type I error we're willing to accept. Represents the threshold for "statistical significance."</p>
                    <p><strong>Common levels:</strong></p>
                    <p>‚Ä¢ Œ± = 0.01 (1%): Very stringent, for critical decisions</p>
                    <p>‚Ä¢ Œ± = 0.05 (5%): Standard in most research</p>
                    <p>‚Ä¢ Œ± = 0.10 (10%): More lenient, exploratory research</p>
                    <p>Critical regions are determined by Œ±: For two-tailed tests, split Œ±/2 in each tail</p>
                </div>
                <div class="step-card">
                    <div class="step-number">3</div>
                    <h3>Calculate Test Statistic</h3>
                    <p>Compute the appropriate test statistic from sample data:</p>
                    <p><strong>Z-score:</strong> z = (xÃÑ - Œº‚ÇÄ) / (œÉ / ‚àön) when œÉ is known</p>
                    <p><strong>T-score:</strong> t = (xÃÑ - Œº‚ÇÄ) / (s / ‚àön) when œÉ is unknown</p>
                    <p><strong>Degrees of Freedom:</strong> df = n - 1 for t-tests</p>
                    <p>The test statistic measures how many standard errors the sample statistic is from the hypothesized parameter.</p>
                </div>
                <div class="step-card">
                    <div class="step-number">4</div>
                    <h3>Make Decision & Interpret</h3>
                    <p><strong>Two methods for decision:</strong></p>
                    <p>1. <strong>P-value approach:</strong> If p-value < Œ±, reject H‚ÇÄ</p>
                    <p>2. <strong>Critical value approach:</strong> If test statistic falls in critical region, reject H‚ÇÄ</p>
                    <p><strong>Conclusion:</strong> State decision in context of the original problem with practical interpretation, not just statistical significance.</p>
                </div>
            </div>

            <div class="theory-box">
                <h3>Types of Errors in Hypothesis Testing</h3>
                <div class="error-grid">
                    <div class="error-card type1">
                        <h4>Type I Error (Œ±) - False Positive</h4>
                        <p><strong>Definition:</strong> Rejecting a true null hypothesis H‚ÇÄ</p>
                        <p><strong>Probability:</strong> P(Type I Error) = Œ± (significance level)</p>
                        <p><strong>Consequence:</strong> Claiming an effect exists when it doesn't</p>
                        <p class="error-example"><strong>Example:</strong> Convicting an innocent person, concluding a drug works when it doesn't (false alarm)</p>
                        <p><strong>Control:</strong> Set a lower Œ± (e.g., 0.01 instead of 0.05)</p>
                    </div>
                    <div class="error-card type2">
                        <h4>Type II Error (Œ≤) - False Negative</h4>
                        <p><strong>Definition:</strong> Failing to reject a false null hypothesis H‚ÇÄ</p>
                        <p><strong>Probability:</strong> P(Type II Error) = Œ≤</p>
                        <p><strong>Power:</strong> 1 - Œ≤ = probability of correctly rejecting false H‚ÇÄ</p>
                        <p class="error-example"><strong>Example:</strong> Acquitting a guilty person, concluding a drug doesn't work when it does (missed detection)</p>
                        <p><strong>Control:</strong> Increase sample size, use higher Œ±, or increase effect size</p>
                    </div>
                </div>
                <div style="margin-top: 1.5rem; padding: 1rem; background: rgba(255,255,255,0.5); border-radius: 8px;">
                    <strong>Trade-off:</strong> Decreasing Œ± (Type I error) increases Œ≤ (Type II error) and vice versa. The ideal balance depends on the relative costs of each type of error in your specific context.
                    <br><br>
                    <strong>Statistical Power:</strong> Power = 1 - Œ≤. Typically aim for power ‚â• 0.80 (80% chance of detecting a real effect)
                </div>
            </div>

            <div class="interactive-box">
                <h3>Understanding P-Values</h3>
                <p><strong>Definition:</strong> The p-value is the probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis H‚ÇÄ is true.</p>
                <p><strong>Formula:</strong> p-value = P(observing test statistic ‚â• |observed value| | H‚ÇÄ is true)</p>
                <p><strong>Interpretation Guide:</strong> Lower p-values provide stronger evidence against H‚ÇÄ</p>
                <div class="p-value-scale">
                    <div class="p-value-marker" data-value="0.001">p < 0.01<br><span>Very Strong Evidence Against H‚ÇÄ</span></div>
                    <div class="p-value-marker" data-value="0.01">0.01 ‚â§ p < 0.05<br><span>Strong Evidence Against H‚ÇÄ</span></div>
                    <div class="p-value-marker" data-value="0.05">0.05 ‚â§ p < 0.10<br><span>Moderate Evidence Against H‚ÇÄ</span></div>
                    <div class="p-value-marker" data-value="0.10">p ‚â• 0.10<br><span>Weak/No Evidence Against H‚ÇÄ</span></div>
                </div>
                <p style="margin-top: 1rem;"><strong>Important:</strong> A p-value is NOT the probability that H‚ÇÄ is true! It's the probability of the data given H‚ÇÄ is true. Also, "not significant" does NOT prove H‚ÇÄ is true.</p>
            </div>
        </div>
    </section>

    <!-- Confidence Intervals Section -->
    <section id="confidence" class="section">
        <div class="container">
            <h2 class="section-title">Confidence Intervals</h2>
            
            <div class="info-box">
                <p class="intro-text">A confidence interval (CI) provides a range of plausible values for an unknown population parameter, constructed from sample data. The confidence level represents the long-run proportion of such intervals that would contain the true parameter if we repeated the sampling process many times.</p>
            </div>

            <div class="formula-box">
                <h3>Confidence Interval Formulas</h3>
                <div class="formula">
                    <strong>General Form:</strong> CI = Point Estimate ¬± Margin of Error
                    <br>CI = Point Estimate ¬± (Critical Value √ó Standard Error)
                </div>
                
                <div class="formula-explanation">
                    <p><strong>1. For Population Mean Œº (œÉ known, or n ‚â• 30):</strong></p>
                    <div class="formula">
                        xÃÑ ¬± z<sub>Œ±/2</sub> √ó (œÉ / ‚àön)
                        <br><br>
                        Where: xÃÑ = sample mean, z<sub>Œ±/2</sub> = critical z-value, 
                        <br>œÉ = population standard deviation, n = sample size
                        <br><strong>Standard Error:</strong> SE = œÉ / ‚àön
                        <br><strong>Margin of Error:</strong> ME = z<sub>Œ±/2</sub> √ó SE
                    </div>
                </div>
                
                <div class="formula-explanation">
                    <p><strong>2. For Population Mean Œº (œÉ unknown, small sample):</strong></p>
                    <div class="formula">
                        xÃÑ ¬± t<sub>Œ±/2, df</sub> √ó (s / ‚àön)
                        <br><br>
                        Where: s = sample standard deviation, 
                        <br>t<sub>Œ±/2, df</sub> = critical t-value with df = n - 1 degrees of freedom
                        <br><strong>Standard Error:</strong> SE = s / ‚àön
                        <br><strong>Use when:</strong> n < 30 and population is approximately normal
                    </div>
                </div>
                
                <div class="formula-explanation">
                    <p><strong>3. For Population Proportion p:</strong></p>
                    <div class="formula">
                        pÃÇ ¬± z<sub>Œ±/2</sub> √ó ‚àö[pÃÇ(1 - pÃÇ) / n]
                        <br><br>
                        Where: pÃÇ = sample proportion = x / n
                        <br>x = number of successes, n = sample size
                        <br><strong>Standard Error:</strong> SE = ‚àö[pÃÇ(1 - pÃÇ) / n]
                        <br><strong>Condition:</strong> npÃÇ ‚â• 10 and n(1 - pÃÇ) ‚â• 10
                    </div>
                </div>
                
                <div class="formula-explanation">
                    <p><strong>4. For Difference Between Two Means (independent samples):</strong></p>
                    <div class="formula">
                        (xÃÑ‚ÇÅ - xÃÑ‚ÇÇ) ¬± t<sub>Œ±/2, df</sub> √ó ‚àö[(s‚ÇÅ¬≤ / n‚ÇÅ) + (s‚ÇÇ¬≤ / n‚ÇÇ)]
                        <br><br>
                        Where: xÃÑ‚ÇÅ, xÃÑ‚ÇÇ = sample means, s‚ÇÅ, s‚ÇÇ = sample standard deviations
                        <br>n‚ÇÅ, n‚ÇÇ = sample sizes
                        <br><strong>Pooled Standard Error:</strong> SE = ‚àö[(s‚ÇÅ¬≤ / n‚ÇÅ) + (s‚ÇÇ¬≤ / n‚ÇÇ)]
                    </div>
                </div>
            </div>

            <div class="confidence-levels">
                <h3>Common Confidence Levels & Critical Values</h3>
                <div class="level-grid">
                    <div class="level-card">
                        <div class="level-percent">90%</div>
                        <p><strong>z<sub>Œ±/2</sub> = 1.645</strong></p>
                        <p>Œ± = 0.10, Œ±/2 = 0.05</p>
                        <p class="level-desc">Narrower interval, less confident</p>
                        <p>Used for: Preliminary studies</p>
                    </div>
                    <div class="level-card featured">
                        <div class="level-percent">95%</div>
                        <p><strong>z<sub>Œ±/2</sub> = 1.96</strong></p>
                        <p>Œ± = 0.05, Œ±/2 = 0.025</p>
                        <p class="level-desc">Standard in most research</p>
                        <p>Used for: General research, publications</p>
                    </div>
                    <div class="level-card">
                        <div class="level-percent">99%</div>
                        <p><strong>z<sub>Œ±/2</sub> = 2.576</strong></p>
                        <p>Œ± = 0.01, Œ±/2 = 0.005</p>
                        <p class="level-desc">Wider interval, more confident</p>
                        <p>Used for: Critical decisions, medical studies</p>
                    </div>
                </div>
                <p style="text-align: center; margin-top: 1.5rem; padding: 1rem; background: rgba(255,255,255,0.5); border-radius: 8px;">
                    <strong>Relationship:</strong> Confidence Level = (1 - Œ±) √ó 100%
                    <br><strong>Width Trade-off:</strong> Higher confidence ‚Üí Wider interval ‚Üí Less precision
                    <br><strong>Sample Size Effect:</strong> Larger n ‚Üí Smaller SE ‚Üí Narrower interval (more precision)
                </p>
            </div>

            <div class="interpretation-box">
                <h3>Correct Interpretation of Confidence Intervals</h3>
                <div class="interpretation-content">
                    <div class="correct">
                        <strong>‚úì CORRECT Interpretations:</strong>
                        <p>‚Ä¢ "We are 95% confident that the true population mean Œº lies between [lower, upper]"</p>
                        <p>‚Ä¢ "If we repeated this sampling process many times, about 95% of the constructed intervals would contain the true Œº"</p>
                        <p>‚Ä¢ "The interval [lower, upper] was constructed using a method that captures the true parameter 95% of the time"</p>
                    </div>
                    <div class="incorrect">
                        <strong>‚úó INCORRECT Interpretations:</strong>
                        <p>‚Ä¢ "There is a 95% probability that Œº is in this interval" (Œº is fixed, not random!)</p>
                        <p>‚Ä¢ "95% of the data falls in this interval" (CI is for the parameter, not data)</p>
                        <p>‚Ä¢ "There is a 95% chance the interval contains Œº" (after construction, it either does or doesn't)</p>
                    </div>
                    <p class="note">
                        <strong>Key Understanding:</strong> The confidence level (95%) refers to the procedure, not a specific interval. Once calculated, a particular interval either contains the true parameter (with certainty) or it doesn't. The "confidence" is in the method's long-run success rate.
                        <br><br>
                        <strong>Factors Affecting Width:</strong>
                        <br>‚Ä¢ Sample size (n) ‚Üë ‚Üí Width ‚Üì
                        <br>‚Ä¢ Confidence level ‚Üë ‚Üí Width ‚Üë
                        <br>‚Ä¢ Population variability (œÉ) ‚Üë ‚Üí Width ‚Üë
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Statistical Tests Section -->
    <section id="tests" class="section bg-alternate">
        <div class="container">
            <h2 class="section-title">Statistical Tests</h2>

            <!-- T-Tests -->
            <div class="test-category">
                <h3 class="category-title">T-Tests (When œÉ is Unknown)</h3>
                <div class="test-grid">
                    <div class="test-card">
                        <h4>One-Sample T-Test</h4>
                        <p class="test-purpose"><strong>Purpose:</strong> Compare sample mean xÃÑ to a known/hypothesized population mean Œº‚ÇÄ</p>
                        <div class="test-formula">
                            <strong>Test Statistic:</strong>
                            <br>t = (xÃÑ - Œº‚ÇÄ) / (s / ‚àön)
                            <br><br>
                            <strong>Where:</strong>
                            <br>‚Ä¢ xÃÑ = sample mean
                            <br>‚Ä¢ Œº‚ÇÄ = hypothesized population mean
                            <br>‚Ä¢ s = sample standard deviation
                            <br>‚Ä¢ n = sample size
                            <br>‚Ä¢ df = n - 1 (degrees of freedom)
                            <br><br>
                            <strong>Standard Error:</strong> SE = s / ‚àön
                        </div>
                        <p class="test-example">
                            <strong>Example:</strong> Does the average height of students (xÃÑ = 170 cm) differ from the national average (Œº‚ÇÄ = 168 cm)?
                            <br><strong>Hypotheses:</strong> H‚ÇÄ: Œº = 168 vs H‚ÇÅ: Œº ‚â† 168
                        </p>
                        <p><strong>Assumptions:</strong> Random sample, approximately normal distribution (or n ‚â• 30)</p>
                    </div>
                    <div class="test-card">
                        <h4>Two-Sample T-Test (Independent)</h4>
                        <p class="test-purpose"><strong>Purpose:</strong> Compare means of two independent populations</p>
                        <div class="test-formula">
                            <strong>Test Statistic:</strong>
                            <br>t = (xÃÑ‚ÇÅ - xÃÑ‚ÇÇ) / ‚àö[(s‚ÇÅ¬≤ / n‚ÇÅ) + (s‚ÇÇ¬≤ / n‚ÇÇ)]
                            <br><br>
                            <strong>Pooled Variance Method (when œÉ‚ÇÅ = œÉ‚ÇÇ):</strong>
                            <br>s<sub>p</sub>¬≤ = [(n‚ÇÅ-1)s‚ÇÅ¬≤ + (n‚ÇÇ-1)s‚ÇÇ¬≤] / (n‚ÇÅ + n‚ÇÇ - 2)
                            <br>t = (xÃÑ‚ÇÅ - xÃÑ‚ÇÇ) / [s<sub>p</sub> √ó ‚àö(1/n‚ÇÅ + 1/n‚ÇÇ)]
                            <br>df = n‚ÇÅ + n‚ÇÇ - 2
                            <br><br>
                            <strong>Welch's Method (unequal variances):</strong>
                            <br>df ‚âà smaller of (n‚ÇÅ-1, n‚ÇÇ-1)
                        </div>
                        <p class="test-example">
                            <strong>Example:</strong> Do males (xÃÑ‚ÇÅ = 82) and females (xÃÑ‚ÇÇ = 78) have different average test scores?
                            <br><strong>Hypotheses:</strong> H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ vs H‚ÇÅ: Œº‚ÇÅ ‚â† Œº‚ÇÇ
                        </p>
                        <p><strong>Assumptions:</strong> Independent samples, normal distributions, homogeneity of variance</p>
                    </div>
                    <div class="test-card">
                        <h4>Paired T-Test (Dependent)</h4>
                        <p class="test-purpose"><strong>Purpose:</strong> Compare means of related/paired observations (before/after, matched pairs)</p>
                        <div class="test-formula">
                            <strong>Test Statistic:</strong>
                            <br>t = dÃÑ / (s<sub>d</sub> / ‚àön)
                            <br><br>
                            <strong>Where:</strong>
                            <br>‚Ä¢ dÃÑ = mean of differences = Œ£d<sub>i</sub> / n
                            <br>‚Ä¢ d<sub>i</sub> = x<sub>i,before</sub> - x<sub>i,after</sub>
                            <br>‚Ä¢ s<sub>d</sub> = standard deviation of differences
                            <br>‚Ä¢ s<sub>d</sub> = ‚àö[Œ£(d<sub>i</sub> - dÃÑ)¬≤ / (n-1)]
                            <br>‚Ä¢ df = n - 1 (number of pairs - 1)
                        </div>
                        <p class="test-example">
                            <strong>Example:</strong> Did blood pressure decrease after treatment? Before: 140 mmHg, After: 132 mmHg
                            <br><strong>Hypotheses:</strong> H‚ÇÄ: Œº<sub>d</sub> = 0 vs H‚ÇÅ: Œº<sub>d</sub> > 0 (one-tailed for decrease)
                        </p>
                        <p><strong>Assumptions:</strong> Paired observations, differences are approximately normal</p>
                    </div>
                </div>
            </div>

            <!-- ANOVA -->
            <div class="test-category">
                <h3 class="category-title">ANOVA (Analysis of Variance)</h3>
                <div class="anova-box">
                    <p class="test-purpose"><strong>Purpose:</strong> Compare means across three or more independent groups simultaneously (extension of t-test)</p>
                    <div class="test-formula">
                        <strong>F-Test Statistic:</strong>
                        <br>F = MS<sub>between</sub> / MS<sub>within</sub> = (Between-Group Variance) / (Within-Group Variance)
                        <br><br>
                        <strong>Sum of Squares:</strong>
                        <br>‚Ä¢ Total: SS<sub>total</sub> = Œ£(x<sub>ij</sub> - xÃÑ<sub>grand</sub>)¬≤
                        <br>‚Ä¢ Between Groups: SS<sub>between</sub> = Œ£n<sub>i</sub>(xÃÑ<sub>i</sub> - xÃÑ<sub>grand</sub>)¬≤
                        <br>‚Ä¢ Within Groups: SS<sub>within</sub> = Œ£(x<sub>ij</sub> - xÃÑ<sub>i</sub>)¬≤
                        <br><br>
                        <strong>Mean Squares:</strong>
                        <br>‚Ä¢ MS<sub>between</sub> = SS<sub>between</sub> / df<sub>between</sub>
                        <br>‚Ä¢ MS<sub>within</sub> = SS<sub>within</sub> / df<sub>within</sub>
                        <br><br>
                        <strong>Degrees of Freedom:</strong>
                        <br>‚Ä¢ df<sub>between</sub> = k - 1 (k = number of groups)
                        <br>‚Ä¢ df<sub>within</sub> = N - k (N = total sample size)
                        <br>‚Ä¢ df<sub>total</sub> = N - 1
                    </div>
                    <div class="anova-components">
                        <div class="component">
                            <strong>Between-Group Variation:</strong> Measures differences among group means. Large values suggest groups have different means.
                        </div>
                        <div class="component">
                            <strong>Within-Group Variation:</strong> Measures variability within each group (error/noise). Used as baseline for comparison.
                        </div>
                    </div>
                    <p class="test-example">
                        <strong>Example:</strong> Do students from three teaching methods (A, B, C) have different average scores?
                        <br><strong>Hypotheses:</strong> H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ vs H‚ÇÅ: At least one mean differs
                        <br><strong>Post-hoc:</strong> If F is significant, use Tukey HSD or Bonferroni to find which pairs differ
                    </p>
                    <p><strong>Assumptions:</strong> Independence, normality within groups, homogeneity of variance (equal variances)</p>
                </div>
            </div>

            <!-- Chi-Square Tests -->
            <div class="test-category">
                <h3 class="category-title">Chi-Square (œá¬≤) Tests</h3>
                <div class="test-grid">
                    <div class="test-card">
                        <h4>Chi-Square Goodness-of-Fit Test</h4>
                        <p class="test-purpose"><strong>Purpose:</strong> Test if observed frequencies match an expected probability distribution</p>
                        <div class="test-formula">
                            <strong>Test Statistic:</strong>
                            <br>œá¬≤ = Œ£ [(O<sub>i</sub> - E<sub>i</sub>)¬≤ / E<sub>i</sub>]
                            <br><br>
                            <strong>Where:</strong>
                            <br>‚Ä¢ O<sub>i</sub> = observed frequency in category i
                            <br>‚Ä¢ E<sub>i</sub> = expected frequency in category i
                            <br>‚Ä¢ Sum over all k categories
                            <br>‚Ä¢ df = k - 1 - p (p = parameters estimated)
                            <br><br>
                            <strong>Expected Frequency:</strong>
                            <br>E<sub>i</sub> = n √ó P<sub>i</sub> (n = total, P<sub>i</sub> = expected proportion)
                        </div>
                        <p class="test-example">
                            <strong>Example:</strong> Is a die fair? Roll 600 times, expect each face 100 times
                            <br><strong>Hypotheses:</strong> H‚ÇÄ: Die is fair (P‚ÇÅ=P‚ÇÇ=...=P‚ÇÜ=1/6) vs H‚ÇÅ: Die is not fair
                        </p>
                        <p><strong>Condition:</strong> All E<sub>i</sub> ‚â• 5</p>
                    </div>
                    <div class="test-card">
                        <h4>Chi-Square Test of Independence</h4>
                        <p class="test-purpose"><strong>Purpose:</strong> Test if two categorical variables are independent (contingency table analysis)</p>
                        <div class="test-formula">
                            <strong>Test Statistic:</strong>
                            <br>œá¬≤ = Œ£ [(O<sub>ij</sub> - E<sub>ij</sub>)¬≤ / E<sub>ij</sub>]
                            <br><br>
                            <strong>Expected Frequency:</strong>
                            <br>E<sub>ij</sub> = (Row<sub>i</sub> Total √ó Column<sub>j</sub> Total) / Grand Total
                            <br><br>
                            <strong>Degrees of Freedom:</strong>
                            <br>df = (r - 1) √ó (c - 1)
                            <br>r = number of rows, c = number of columns
                        </div>
                        <p class="test-example">
                            <strong>Example:</strong> Is smoking status independent of gender?
                            <br><strong>Hypotheses:</strong> H‚ÇÄ: Variables are independent vs H‚ÇÅ: Variables are dependent
                        </p>
                        <p><strong>Condition:</strong> At least 80% of cells have E<sub>ij</sub> ‚â• 5</p>
                    </div>
                </div>
            </div>

            <!-- Z-Test -->
            <div class="test-category">
                <h3 class="category-title">Z-Test (When œÉ is Known)</h3>
                <div class="test-card single">
                    <h4>One-Sample Z-Test for Mean</h4>
                    <p class="test-purpose"><strong>Purpose:</strong> Test hypothesis about population mean when population standard deviation œÉ is known</p>
                    <div class="test-formula">
                        <strong>Test Statistic:</strong>
                        <br>z = (xÃÑ - Œº‚ÇÄ) / (œÉ / ‚àön)
                        <br><br>
                        <strong>Where:</strong>
                        <br>‚Ä¢ xÃÑ = sample mean
                        <br>‚Ä¢ Œº‚ÇÄ = hypothesized population mean
                        <br>‚Ä¢ œÉ = known population standard deviation
                        <br>‚Ä¢ n = sample size
                        <br><br>
                        <strong>Standard Error:</strong> SE = œÉ / ‚àön
                        <br><br>
                        <strong>Critical Values (two-tailed):</strong>
                        <br>‚Ä¢ Œ± = 0.05: z = ¬±1.96
                        <br>‚Ä¢ Œ± = 0.01: z = ¬±2.576
                        <br>‚Ä¢ Œ± = 0.10: z = ¬±1.645
                    </div>
                    <p class="test-example">
                        <strong>Example:</strong> Testing if sample mean differs from known population mean when œÉ is known
                        <br><strong>Use when:</strong> œÉ known, large sample (n ‚â• 30), or population is normal
                    </p>
                    <p><strong>Z-Test for Proportions:</strong> z = (pÃÇ - p‚ÇÄ) / ‚àö[p‚ÇÄ(1-p‚ÇÄ)/n]</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Regression Section -->
    <section id="regression" class="section">
        <div class="container">
            <h2 class="section-title">Regression Analysis</h2>
            
            <div class="info-box">
                <p class="intro-text">Regression analysis is a powerful statistical method used to model and examine the relationship between one dependent variable (Y) and one or more independent variables (X). It allows us to predict outcomes, quantify relationships, and test hypotheses about how variables relate to each other.</p>
            </div>

            <div class="regression-types">
                <div class="regression-card">
                    <h3>Simple Linear Regression</h3>
                    <p><strong>Purpose:</strong> Model the linear relationship between one predictor (X) and one response variable (Y)</p>
                    <div class="formula">
                        <strong>Regression Equation:</strong>
                        <br>≈∑ = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œµ
                        <br><br>
                        <strong>Where:</strong>
                        <br>‚Ä¢ ≈∑ = Predicted value of Y
                        <br>‚Ä¢ Œ≤‚ÇÄ = Y-intercept (value of Y when X = 0)
                        <br>‚Ä¢ Œ≤‚ÇÅ = Slope (change in Y per one-unit change in X)
                        <br>‚Ä¢ x = Independent variable (predictor)
                        <br>‚Ä¢ Œµ = Error term (residual)
                    </div>
                    <div class="formula-parts">
                        <p><strong>Calculating Slope (Œ≤‚ÇÅ):</strong></p>
                        <div class="formula">
                            Œ≤‚ÇÅ = Œ£[(x<sub>i</sub> - xÃÑ)(y<sub>i</sub> - »≥)] / Œ£(x<sub>i</sub> - xÃÑ)¬≤
                            <br>OR: Œ≤‚ÇÅ = r √ó (s<sub>y</sub> / s<sub>x</sub>)
                        </div>
                        <p><strong>Calculating Intercept (Œ≤‚ÇÄ):</strong></p>
                        <div class="formula">
                            Œ≤‚ÇÄ = »≥ - Œ≤‚ÇÅxÃÑ
                        </div>
                        <p style="margin-top: 0.5rem;"><strong>Where:</strong> r = correlation coefficient, s<sub>x</sub> = SD of X, s<sub>y</sub> = SD of Y</p>
                    </div>
                </div>

                <div class="regression-card">
                    <h3>Multiple Linear Regression</h3>
                    <p><strong>Purpose:</strong> Predict Y using multiple predictor variables X‚ÇÅ, X‚ÇÇ, ..., X<sub>k</sub></p>
                    <div class="formula">
                        <strong>Regression Equation:</strong>
                        <br>≈∑ = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤<sub>k</sub>x<sub>k</sub> + Œµ
                        <br><br>
                        <strong>Where:</strong>
                        <br>‚Ä¢ Œ≤‚ÇÄ = Intercept
                        <br>‚Ä¢ Œ≤<sub>i</sub> = Partial regression coefficient for X<sub>i</sub>
                        <br>‚Ä¢ Œ≤<sub>i</sub> represents the change in Y for one-unit change in X<sub>i</sub>, holding all other predictors constant
                    </div>
                    <p class="formula-desc">
                        <strong>Key Advantage:</strong> Controls for confounding variables and provides better predictions
                        <br><strong>Matrix Form:</strong> Y = XŒ≤ + Œµ, solved using: Œ≤ = (X'X)‚Åª¬πX'Y
                    </p>
                </div>
            </div>

            <div class="regression-metrics">
                <h3>Key Regression Metrics & Formulas</h3>
                <div class="metric-grid">
                    <div class="metric-card">
                        <h4>R¬≤ (Coefficient of Determination)</h4>
                        <p><strong>Definition:</strong> Proportion of variance in Y explained by X</p>
                        <div class="formula">
                            R¬≤ = 1 - (SS<sub>residual</sub> / SS<sub>total</sub>)
                            <br>R¬≤ = SS<sub>regression</sub> / SS<sub>total</sub>
                            <br><br>
                            <strong>Where:</strong>
                            <br>‚Ä¢ SS<sub>total</sub> = Œ£(y<sub>i</sub> - »≥)¬≤
                            <br>‚Ä¢ SS<sub>regression</sub> = Œ£(≈∑<sub>i</sub> - »≥)¬≤
                            <br>‚Ä¢ SS<sub>residual</sub> = Œ£(y<sub>i</sub> - ≈∑<sub>i</sub>)¬≤
                        </div>
                        <p class="metric-range"><strong>Range:</strong> 0 to 1 (0% to 100%)</p>
                        <p><strong>Interpretation:</strong> R¬≤ = 0.75 means 75% of variance in Y is explained by X</p>
                        <p><strong>Adjusted R¬≤:</strong> R¬≤<sub>adj</sub> = 1 - [(1-R¬≤)(n-1)/(n-k-1)] (penalizes extra predictors)</p>
                    </div>
                    <div class="metric-card">
                        <h4>Correlation Coefficient (r)</h4>
                        <p><strong>Definition:</strong> Measures strength and direction of linear relationship</p>
                        <div class="formula">
                            r = Œ£[(x<sub>i</sub> - xÃÑ)(y<sub>i</sub> - »≥)] / ‚àö[Œ£(x<sub>i</sub> - xÃÑ)¬≤ √ó Œ£(y<sub>i</sub> - »≥)¬≤]
                            <br><br>
                            <strong>Relationship with R¬≤:</strong>
                            <br>R¬≤ = r¬≤ (in simple linear regression)
                            <br>r = ¬±‚àöR¬≤ (sign matches slope Œ≤‚ÇÅ)
                        </div>
                        <p class="metric-range"><strong>Range:</strong> -1 to +1</p>
                        <div class="correlation-scale">
                            <span>-1 (Perfect Negative)</span>
                            <span>0 (No Correlation)</span>
                            <span>1 (Perfect Positive)</span>
                        </div>
                        <p><strong>Interpretation:</strong> |r| > 0.7 = strong, 0.3-0.7 = moderate, < 0.3 = weak</p>
                    </div>
                    <div class="metric-card">
                        <h4>Standard Error of Estimate (SE<sub>est</sub>)</h4>
                        <p><strong>Definition:</strong> Average distance of observed Y values from regression line</p>
                        <div class="formula">
                            SE<sub>est</sub> = ‚àö[Œ£(y<sub>i</sub> - ≈∑<sub>i</sub>)¬≤ / (n - 2)]
                            <br>SE<sub>est</sub> = ‚àö[SS<sub>residual</sub> / (n - 2)]
                            <br><br>
                            <strong>Also called:</strong> Root Mean Square Error (RMSE)
                            <br><strong>Interpretation:</strong> Units of Y variable
                        </div>
                        <p class="metric-range"><strong>Better fit:</strong> Lower SE<sub>est</sub> values</p>
                        <p><strong>Use:</strong> Measures prediction accuracy; construct prediction intervals</p>
                    </div>
                </div>
            </div>

            <div class="assumptions-box">
                <h3>Linear Regression Assumptions (LINE)</h3>
                <div class="assumption-list">
                    <div class="assumption-item">
                        <span class="check">‚úì</span> <strong>L - Linearity:</strong> The relationship between X and Y is linear
                        <br><strong>Check:</strong> Scatter plot should show linear pattern
                        <br><strong>Fix:</strong> Transform variables (log, square root) or use polynomial regression
                    </div>
                    <div class="assumption-item">
                        <span class="check">‚úì</span> <strong>I - Independence:</strong> Observations are independent of each other (no autocorrelation)
                        <br><strong>Check:</strong> Durbin-Watson test, plot residuals over time
                        <br><strong>Violation:</strong> Common in time series data
                    </div>
                    <div class="assumption-item">
                        <span class="check">‚úì</span> <strong>N - Normality:</strong> Residuals (errors) are approximately normally distributed
                        <br><strong>Check:</strong> Q-Q plot, histogram of residuals, Shapiro-Wilk test
                        <br><strong>Note:</strong> Most critical for small samples (n < 30)
                    </div>
                    <div class="assumption-item">
                        <span class="check">‚úì</span> <strong>E - Equal Variance (Homoscedasticity):</strong> Constant variance of residuals across all values of X
                        <br><strong>Check:</strong> Residual plot (residuals vs. fitted values should show random scatter)
                        <br><strong>Fix:</strong> Transform Y variable or use weighted least squares
                    </div>
                </div>
                <p style="margin-top: 1.5rem; padding: 1rem; background: rgba(255,255,255,0.6); border-radius: 8px; border-left: 4px solid #14b8a6;">
                    <strong>Additional Considerations:</strong>
                    <br>‚Ä¢ <strong>No Multicollinearity:</strong> (Multiple regression) Predictors should not be highly correlated with each other (check VIF < 10)
                    <br>‚Ä¢ <strong>No Outliers/Influential Points:</strong> Check Cook's distance, leverage, DFFIT
                    <br>‚Ä¢ <strong>Residual Formula:</strong> e<sub>i</sub> = y<sub>i</sub> - ≈∑<sub>i</sub> (observed - predicted)
                </p>
            </div>
        </div>
    </section>

    <!-- Interactive Calculator Section -->
    <section id="calculator" class="section bg-alternate">
        <div class="container">
            <h2 class="section-title">Statistical Calculators</h2>
            
            <div class="calculator-tabs">
                <button class="tab-button active" data-tab="ttest">T-Test</button>
                <button class="tab-button" data-tab="ci">Confidence Interval</button>
                <button class="tab-button" data-tab="ztest">Z-Test</button>
                <button class="tab-button" data-tab="correlation">Correlation</button>
            </div>

            <!-- T-Test Calculator -->
            <div id="ttest" class="calculator-content active">
                <h3>One-Sample T-Test Calculator</h3>
                <div class="calculator-form">
                    <div class="form-group">
                        <label for="sample-mean">Sample Mean (xÃÑ):</label>
                        <input type="number" id="sample-mean" step="0.01" placeholder="e.g., 75.5">
                    </div>
                    <div class="form-group">
                        <label for="pop-mean">Population Mean (Œº‚ÇÄ):</label>
                        <input type="number" id="pop-mean" step="0.01" placeholder="e.g., 70">
                    </div>
                    <div class="form-group">
                        <label for="sample-sd">Sample Standard Deviation (s):</label>
                        <input type="number" id="sample-sd" step="0.01" placeholder="e.g., 8.5">
                    </div>
                    <div class="form-group">
                        <label for="sample-size">Sample Size (n):</label>
                        <input type="number" id="sample-size" min="2" placeholder="e.g., 30">
                    </div>
                    <div class="form-group">
                        <label for="alpha-level">Significance Level (Œ±):</label>
                        <select id="alpha-level">
                            <option value="0.01">0.01</option>
                            <option value="0.05" selected>0.05</option>
                            <option value="0.10">0.10</option>
                        </select>
                    </div>
                    <button class="calculate-btn" onclick="calculateTTest()">Calculate</button>
                </div>
                <div id="ttest-result" class="result-box"></div>
            </div>

            <!-- Confidence Interval Calculator -->
            <div id="ci" class="calculator-content">
                <h3>Confidence Interval Calculator</h3>
                <div class="calculator-form">
                    <div class="form-group">
                        <label for="ci-mean">Sample Mean (xÃÑ):</label>
                        <input type="number" id="ci-mean" step="0.01" placeholder="e.g., 100">
                    </div>
                    <div class="form-group">
                        <label for="ci-sd">Standard Deviation (s):</label>
                        <input type="number" id="ci-sd" step="0.01" placeholder="e.g., 15">
                    </div>
                    <div class="form-group">
                        <label for="ci-size">Sample Size (n):</label>
                        <input type="number" id="ci-size" min="2" placeholder="e.g., 50">
                    </div>
                    <div class="form-group">
                        <label for="confidence-level">Confidence Level:</label>
                        <select id="confidence-level">
                            <option value="90">90%</option>
                            <option value="95" selected>95%</option>
                            <option value="99">99%</option>
                        </select>
                    </div>
                    <button class="calculate-btn" onclick="calculateCI()">Calculate</button>
                </div>
                <div id="ci-result" class="result-box"></div>
            </div>

            <!-- Z-Test Calculator -->
            <div id="ztest" class="calculator-content">
                <h3>Z-Test Calculator</h3>
                <div class="calculator-form">
                    <div class="form-group">
                        <label for="z-sample-mean">Sample Mean (xÃÑ):</label>
                        <input type="number" id="z-sample-mean" step="0.01" placeholder="e.g., 105">
                    </div>
                    <div class="form-group">
                        <label for="z-pop-mean">Population Mean (Œº):</label>
                        <input type="number" id="z-pop-mean" step="0.01" placeholder="e.g., 100">
                    </div>
                    <div class="form-group">
                        <label for="z-pop-sd">Population Standard Deviation (œÉ):</label>
                        <input type="number" id="z-pop-sd" step="0.01" placeholder="e.g., 15">
                    </div>
                    <div class="form-group">
                        <label for="z-sample-size">Sample Size (n):</label>
                        <input type="number" id="z-sample-size" min="1" placeholder="e.g., 100">
                    </div>
                    <div class="form-group">
                        <label for="z-alpha-level">Significance Level (Œ±):</label>
                        <select id="z-alpha-level">
                            <option value="0.01">0.01</option>
                            <option value="0.05" selected>0.05</option>
                            <option value="0.10">0.10</option>
                        </select>
                    </div>
                    <button class="calculate-btn" onclick="calculateZTest()">Calculate</button>
                </div>
                <div id="ztest-result" class="result-box"></div>
            </div>

            <!-- Correlation Calculator -->
            <div id="correlation" class="calculator-content">
                <h3>Correlation Coefficient Calculator</h3>
                <div class="calculator-form">
                    <div class="form-group full-width">
                        <label for="x-values">X Values (comma-separated):</label>
                        <input type="text" id="x-values" placeholder="e.g., 1, 2, 3, 4, 5">
                    </div>
                    <div class="form-group full-width">
                        <label for="y-values">Y Values (comma-separated):</label>
                        <input type="text" id="y-values" placeholder="e.g., 2, 4, 5, 4, 5">
                    </div>
                    <button class="calculate-btn" onclick="calculateCorrelation()">Calculate</button>
                </div>
                <div id="correlation-result" class="result-box"></div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>üìä Inferential Statistics</h3>
                    <p>Your comprehensive guide to statistical inference and hypothesis testing.</p>
                </div>
                <div class="footer-section">
                    <h4>Quick Links</h4>
                    <ul>
                        <li><a href="#intro">Introduction</a></li>
                        <li><a href="#hypothesis">Hypothesis Testing</a></li>
                        <li><a href="#confidence">Confidence Intervals</a></li>
                        <li><a href="#tests">Statistical Tests</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Resources</h4>
                    <ul>
                        <li><a href="#calculator">Calculators</a></li>
                        <li><a href="#regression">Regression</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 Inferential Statistics Tutorial. All rights reserved. Personalized content curated by Prateek Dutta</p>
            </div>
        </div>
    </footer>

    <!-- Scroll to Top Button -->
    <button id="scrollTopBtn" class="scroll-top" onclick="scrollToTop()">‚Üë</button>

    <script src="script.js"></script>
</body>
</html>

